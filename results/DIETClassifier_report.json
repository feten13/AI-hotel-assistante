{
  "children_count": {
    "precision": 0.5,
    "recall": 0.5,
    "f1-score": 0.5,
    "support": 2,
    "confused_with": {}
  },
  "marital_status": {
    "precision": 0.5333333333333333,
    "recall": 1.0,
    "f1-score": 0.6956521739130436,
    "support": 8,
    "confused_with": {}
  },
  "name": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8,
    "confused_with": {}
  },
  "location": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8,
    "confused_with": {}
  },
  "room_type": {
    "precision": 0.6923076923076923,
    "recall": 0.8181818181818182,
    "f1-score": 0.7500000000000001,
    "support": 11,
    "confused_with": {
      "marital_status": 2
    }
  },
  "gendre": {
    "precision": 0.8,
    "recall": 1.0,
    "f1-score": 0.888888888888889,
    "support": 8,
    "confused_with": {}
  },
  "start_date": {
    "precision": 0.6153846153846154,
    "recall": 1.0,
    "f1-score": 0.761904761904762,
    "support": 8,
    "confused_with": {}
  },
  "end_date": {
    "precision": 0.9,
    "recall": 1.0,
    "f1-score": 0.9473684210526316,
    "support": 9,
    "confused_with": {}
  },
  "micro avg": {
    "precision": 0.7468354430379747,
    "recall": 0.9516129032258065,
    "f1-score": 0.8368794326241135,
    "support": 62
  },
  "macro avg": {
    "precision": 0.7551282051282051,
    "recall": 0.9147727272727273,
    "f1-score": 0.8179767807199159,
    "support": 62
  },
  "weighted avg": {
    "precision": 0.7791149710504549,
    "recall": 0.9516129032258065,
    "f1-score": 0.8475464901149555,
    "support": 62
  },
  "accuracy": 0.9605263157894737
}